import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from matplotlib import pyplot as plt
from torchvision import transforms
import torchvision.datasets as dsets
import random
import numpy as np


mnist_train = dsets.MNIST(root="MNIST_data/", train=True, transform=transforms.ToTensor(),download=True)
print(mnist_train)
mnist_test = dsets.MNIST(root="MNIST_data/", train=False, transform=transforms.ToTensor(),download=True)
training_epochs = 1
batch_size = 100
data_loader = torch.utils.data.DataLoader(dataset=mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)

device = 'cuda' if torch.cuda.is_available() else 'cpu'

linear = torch.nn.Linear(784, 10, bias=True).to(device)

torch.nn.init.normal_(linear.weight)

sigmoid = torch.nn.Sigmoid()
# model=torch.nn.Sequential(linear,sigmoid)
criterion = torch.nn.CrossEntropyLoss().to(device)
optimizer = torch.optim.SGD(linear.parameters(), lr=0.1)

for epoch in range(training_epochs):
    avg_cost = 0
    total_batch = len(data_loader)

    for X, Y in data_loader:
        X = X.view(-1, 28 * 28).to(device)
        optimizer.zero_grad()
        hypothesis = linear(X)
        cost = criterion(hypothesis, Y)
        cost.backward()
        optimizer.step()
        avg_cost += cost / total_batch

    print(epoch," : ", avg_cost)
    with torch.no_grad():
        X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)
        Y_test = mnist_test.test_labels.to(device)


        prediction = linear(X_test)
        correct_prediction = torch.argmax(prediction, 1) == Y_test
        accuracy = correct_prediction.float().mean()
        print("Accuracy", accuracy.item())



with torch.no_grad():
    X_test=mnist_test.test_data.view(-1,28*28).float().to(device)
    Y_test=mnist_test.test_labels.to(device)



    prediction=linear(X_test)
    correct_prediction=torch.argmax(prediction,1)==Y_test
    accuracy=correct_prediction.float().mean()
    print("Accuracy", accuracy.item())

    # visualization

    r=random.randint(0,len(mnist_test)-1)
    X_single_data=mnist_test.test_data[r:r+5].view(-1,28*28).float().to(device)
    Y_single_data=mnist_test.test_labels[r:r+5].to(device)

    print("Label: ", Y_single_data)
    single_prediction=linear(X_single_data)
    print("Prediction_softmax: ",F.softmax(single_prediction))
    print("Prediction: ", torch.argmax(single_prediction,1))

    fig, (ax0, ax1,ax2,ax3,ax4) = plt.subplots(1, 5)
    ax0.imshow(mnist_test.test_data[r:r+1].view(28,28), cmap='gray')
    ax1.imshow(mnist_test.test_data[r+1:r+2].view(28,28), cmap='gray');
    ax2.imshow(mnist_test.test_data[r+2:r+3].view(28,28), cmap='gray')
    ax3.imshow(mnist_test.test_data[r+3:r+4].view(28,28), cmap='gray');
    ax4.imshow(mnist_test.test_data[r+4:r+ 5].view(28, 28), cmap='gray');
    plt.show()



