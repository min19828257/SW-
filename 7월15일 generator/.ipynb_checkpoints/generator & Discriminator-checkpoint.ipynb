{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator 모델을 거친뒤 discriminator의 출력값을 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 28, 28])\n",
      "torch.Size([3, 784])\n",
      "torch.Size([3, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        #self.deconv1 = nn.ConvTranspose2d(100,128,3,1,0)\n",
    "        \n",
    "        # MNIST data image of shape 28 * 28 = 784\n",
    "        self.linear1 = torch.nn.Linear(10, 256, bias=True)\n",
    "        self.linear2 = torch.nn.Linear(256, 500, bias=True)\n",
    "        self.linear3 = torch.nn.Linear(500, 200, bias=True)\n",
    "        self.linear4 = torch.nn.Linear(200, 784, bias=True)\n",
    "        \n",
    "        self.LRelu = nn.LeakyReLU(0.2)\n",
    "        \n",
    "    def forward(self,z):\n",
    "        out = self.linear1(z)\n",
    "        out = self.LRelu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.LRelu(out)\n",
    "        out = self.linear3(out)\n",
    "        out = self.LRelu(out)\n",
    "        out = self.linear4(out)\n",
    "        \n",
    "        #이미지 형식(28x28)으로 바꾸기\n",
    "        return out\n",
    "      #  dcl = self.LRelu(self.deconv1(z))\n",
    "\n",
    "batch_size = 3\n",
    "z = torch.rand(batch_size, 10)\n",
    "\n",
    "GAN = Generator()\n",
    "result = GAN.forward(z)\n",
    "result = result.view(batch_size, 1, 28, 28)\n",
    "\n",
    "print(result.size())\n",
    "print(GAN.forward(z).size())\n",
    "print(z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataloader첫번째 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision.transforms import Compose, RandomCrop, ToTensor, Resize\n",
    "\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "import random\n",
    "NUM_EPOCHS = 1\n",
    "loadmodel = None\n",
    "\n",
    "GPUUSE = None\n",
    "\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in ['bmp', '.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG'])\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(512, 1024, kernel_size=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(1024, 1, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.sigmoid(self.net(x))\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 3)\n",
    "        self.conv4 = nn.Conv2d(32, 64, 3)\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 6 * 6, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = x.view(-1, 64 * 6 * 6)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "\n",
    "# save load 코드 예시\n",
    "# torch.save(netD.state_dict(), 'param/netD_epoch_%d.pth' % (epoch))\n",
    "\n",
    "# net.load_state_dict(torch.load(loadmodel))\n",
    "\n",
    "class DatasetFromfolder(Dataset):\n",
    "    def __init__(self, dir_mnist):\n",
    "        super(DatasetFromfolder, self).__init__()\n",
    "        #dir_mnist = 'C:\\Users\\Administrator\\Desktop\\새 폴더\\SW-\\7월15일 generator\\4주차\\mnist_png.tar\\mnist_png\\training'\n",
    "        self.filelist = []\n",
    "        self.lensum = 0\n",
    "        for i in range(10):\n",
    "            idir = join(dir_mnist, str(i))\n",
    "            filelist_tmp = [join(idir, x) for x in listdir(idir) if is_image_file(x)]\n",
    "            self.filelist.append((filelist_tmp, i))\n",
    "            self.lensum = self.lensum + len(filelist_tmp)\n",
    "\n",
    "        self.transform = Compose([ToTensor()])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        c = random.randint(10)\n",
    "        clist, label = self.filelist[c]\n",
    "        resultimage = self.transform(Image.open(clist[index]).convert('L'))\n",
    "\n",
    "        return resultimage, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return  self.lensum\n",
    "\n",
    "\n",
    "def train():\n",
    "    train_set = DatasetFromfolder('./data/1', './data/0')\n",
    "    val_set = DatasetFromfolder('./data1/1', './data1/0')\n",
    "    train_loader = DataLoader(dataset=train_set, num_workers=0, batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(dataset=val_set, num_workers=0, batch_size=1, shuffle=True)\n",
    "\n",
    "    GPUUSE = None\n",
    "\n",
    "    # netD = Discriminator()\n",
    "    netD = Net()\n",
    "    print('# discriminator parameters:', sum(param.numel() for param in netD.parameters()))\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    if loadmodel is not None:\n",
    "        print(\"=> loading checkpoint '{}'\".format(loadmodel))\n",
    "        netD.load_state_dict(torch.load(loadmodel))\n",
    "    if GPUUSE == None:\n",
    "        netD.cpu()\n",
    "    else:\n",
    "        if torch.cuda.is_available():\n",
    "            netD.cuda()\n",
    "\n",
    "    optimizerD = optim.Adam(netD.parameters())\n",
    "\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "\n",
    "        netD.train()\n",
    "        batch_idx = 0\n",
    "        for sample, label in train_loader:\n",
    "            batch_size = sample.size(0)\n",
    "\n",
    "            if GPUUSE == None:\n",
    "                face = sample.cpu()\n",
    "                label = label.cpu()\n",
    "            else:\n",
    "                if torch.cuda.is_available():\n",
    "                    face = sample.cuda()\n",
    "                    label = label.cuda()\n",
    "\n",
    "            netD.zero_grad()\n",
    "            out = netD(face)\n",
    "\n",
    "            d_loss = criterion(out.squeeze(), label.squeeze())\n",
    "            d_loss.backward(retain_graph=True)\n",
    "            optimizerD.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for val_face, val_label in val_loader:\n",
    "                    val_out = netD(val_face)\n",
    "                    Val_loss = criterion(val_out, val_label)\n",
    "                    print('Epoch [{}/{}], BatchStep[{}/{}], Loss: {}'.format(epoch, NUM_EPOCHS, batch_idx, batch_size,\n",
    "                                                                             Val_loss))\n",
    "            batch_idx += 1\n",
    "\n",
    "        torch.save(netD.state_dict(), 'param/netD_epoch_%d.pth' % (epoch))\n",
    "\n",
    "\n",
    "def test(img):\n",
    "    print(\"test session\")\n",
    "\n",
    "    loadmodel = 'param/netD_epoch_1.pth'\n",
    "    # netD = Discriminator()\n",
    "    net = Net()\n",
    "    print('# discriminator parameters:', sum(param.numel() for param in net.parameters()))\n",
    "\n",
    "    if GPUUSE == None:\n",
    "        net.cpu()\n",
    "    else:\n",
    "        if torch.cuda.is_available():\n",
    "            net.cuda()\n",
    "\n",
    "    if loadmodel is not None:\n",
    "        print(\"=> loading checkpoint '{}'\".format(loadmodel))\n",
    "        net.load_state_dict(torch.load(loadmodel))\n",
    "\n",
    "    net.eval()\n",
    "\n",
    "    trans = Compose([Resize([144, 144]), ToTensor()])\n",
    "    img.convert(\"L\")\n",
    "\n",
    "    img = trans(img).unsqueeze(1)\n",
    "    if GPUUSE != None:\n",
    "        img = img.cuda()\n",
    "\n",
    "    output = net(img)\n",
    "\n",
    "    print(\"output : \", output[0])\n",
    "\n",
    "    return output[0]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # train()\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader만 두번째버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from os.path import join\n",
    "from os import listdir\n",
    "\n",
    "class DatasetFromfolder(Dataset):\n",
    "    def __init__(self, dir_mnist):\n",
    "        super(DatasetFromfolder, self).__init__()\n",
    "\n",
    "        self.filelist = []\n",
    "        self.lenlist = []\n",
    "        self.lensum = 0\n",
    "        for i in range(10):\n",
    "            idir = join(dir_mnist, str(i))\n",
    "            filelist_tmp = [join(idir, x) for x in listdir(idir)]\n",
    "            self.filelist.append((filelist_tmp, i))\n",
    "            self.lenlist.append(len(filelist_tmp))\n",
    "            self.lensum = self.lensum + len(filelist_tmp)\n",
    "\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        c, cindex = self._findlabelfromindex(index)\n",
    "        clist, label = self.filelist[c]\n",
    "        resultimage = self.transform(Image.open(clist[cindex]).convert('L'))\n",
    "\n",
    "        return resultimage, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.lensum\n",
    "\n",
    "    def _findlabelfromindex(self, index):\n",
    "        label = 0\n",
    "        indexsum = 0\n",
    "\n",
    "        for i in range(10):\n",
    "            indexsum += self.lenlist[i]\n",
    "            if index < indexsum:\n",
    "                label = i\n",
    "                break\n",
    "\n",
    "        classindex = index - indexsum\n",
    "\n",
    "        return label, classindex"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
